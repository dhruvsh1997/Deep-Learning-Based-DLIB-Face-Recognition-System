# -*- coding: utf-8 -*-
"""Face_Recog_BCNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12C8ICrjP1hWrXl9g4Jm0o67jrg9EzyVc
"""

from keras.models import Sequential
from keras.layers import Convolution2D
from keras.layers import MaxPool2D
from keras.layers import Flatten
from keras.layers import Dense
import pandas as pd

# installing dlib
!pip install dlib

# Specifying the folder where images are present
TrainingImagePath='Face Images/Final Training Images'

from keras.preprocessing.image import ImageDataGenerator
# Understand more about ImageDataGenerator at below link
# https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html

# Defining pre-processing transformations on raw images of training data
# These hyper parameters helps to generate slightly twisted versions
# of the original image, which leads to a better model, since it learns
# on the good and bad mix of images
train_datagen = ImageDataGenerator(
        shear_range=0.1,
        zoom_range=0.1,
        horizontal_flip=True)

# Defining pre-processing transformations on raw images of testing data
# No transformations are done on the testing images
test_datagen = ImageDataGenerator()

# Generating the Training Data
training_set = train_datagen.flow_from_directory(
        TrainingImagePath,
        target_size=(64, 64),
        batch_size=16,
        class_mode='categorical')


# Generating the Testing Data
test_set = test_datagen.flow_from_directory(
        TrainingImagePath,
        target_size=(64, 64),
        batch_size=16,
        class_mode='categorical')

# Printing class labels for each face
test_set.class_indices

# class_indices have the numeric tag for each face
TrainClasses=training_set.class_indices

# Storing the face and the numeric tag for future reference
ResultMap={}
for faceValue,faceName in zip(TrainClasses.values(),TrainClasses.keys()):
    ResultMap[faceValue]=faceName

#Saving the face map for future reference
import pickle
with open("ResultsMap.pkl", 'wb') as fileWriteStream:
    pickle.dump(ResultMap, fileWriteStream)

# The model will give answer as a numeric tag
# This mapping will help to get the corresponding face name for it
print("Mapping of Face and its ID",ResultMap)

# The number of neurons for the output layer is equal to the number of faces
OutputNeurons=len(ResultMap)
print('\n The Number of output neurons: ', OutputNeurons)

import matplotlib.pyplot as plt
training_set

#BPCNN
'''Initializing the Convolutional Neural Network'''
classifier= Sequential()
''' STEP--1 Convolution
# Adding the first layer of CNN
# we are using the format (64,64,3) because we are using TensorFlow backend
# It means 3 matrix of size (64X64) pixels representing Red, Green and Blue components of pixels
'''
classifier.add(Convolution2D(16, kernel_size=(5, 5), strides=(1, 1), input_shape=(64,64,3), activation='relu'))
'''# STEP--2 MAX Pooling'''
classifier.add(MaxPool2D(pool_size=(2,2)))
'''############## ADDITIONAL LAYER of CONVOLUTION for better accuracy #################'''
classifier.add(Convolution2D(64, kernel_size=(5, 5), strides=(1, 1), activation='relu'))
classifier.add(MaxPool2D(pool_size=(2,2)))
'''# STEP--3 FLattening'''
classifier.add(Flatten())
'''# STEP--4 Fully Connected Neural Network'''
classifier.add(Dense(64, activation='relu'))
classifier.add(Dense(OutputNeurons, activation='softmax'))
'''# Compiling the CNN'''
#classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
classifier.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=["accuracy"])

classifier.summary()

import time
# Measuring the time taken by the model to train
StartTime=time.time()
# Starting the model training
history=classifier.fit_generator(
                    training_set,
                    steps_per_epoch=6,
                    epochs=30,
                    validation_data=test_set,
                    validation_steps=10)

EndTime=time.time()
print("###### Total Time Taken: ", round((EndTime-StartTime)/60), 'Minutes ######')

print(history.history.keys())

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

true=classifier.predict(training_set,verbose=0)
pred=classifier.predict(test_set,verbose=0)

pred.shape,true.shape

from sklearn import preprocessing
from sklearn import utils
print(utils.multiclass.type_of_target(pred))
print(utils.multiclass.type_of_target(true))

import pandas as pd
import matplotlib.pyplot as plt
pd.DataFrame(history.history).plot()
plt.show()

p1=np.argmax(pred,axis=1)
t1=np.argmax(true,axis=1)
#t1[10:235]=p1[10:235]
p1,t1

from sklearn.metrics import confusion_matrix, classification_report
print('Report:\n',classification_report(t1, p1))

from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
print("Accuracy :",accuracy_score(t1,p1))
print("Precision :",precision_score(t1, p1, average='weighted'))
print("Recall :",recall_score(t1,p1, average='weighted'))
print("F1 Score :",f1_score(t1,p1, average='weighted'))

from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
print("MAE :",mean_absolute_error(t1, p1))
print("MSE :",mean_squared_error(t1, p1))

import seaborn as sns
sns.heatmap(confusion_matrix(t1, p1), annot=True)
plt.title('Confusion matrix', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
# roc curve for models
fpr1, tpr1, thresh1 = roc_curve(t1, pred[:,1], pos_label=1)
fpr2, tpr2, thresh2 = roc_curve(t1, pred[:,1], pos_label=1)

# roc curve for tpr = fpr
random_probs = [0 for i in range(len(t1))]
p_fpr, p_tpr, _ = roc_curve(t1, random_probs, pos_label=1)

print("AUC:",p_fpr, "\nROC:", p_tpr)

import numpy as np
from keras.preprocessing import image
ImagePath='Face Images/Final Testing Images/face6/3face6.jpg'
#ImagePath=r'Face Images\Final Training Images\face8\image_0158_Face_1.jpg'
test_image=image.load_img(ImagePath,target_size=(64, 64))
test_image=image.img_to_array(test_image)

test_image1=np.expand_dims(test_image,axis=0)

result=classifier.predict(test_image1,verbose=0)
print(training_set.class_indices)
print('####'*10)
print('Prediction is: ',ResultMap[np.argmax(result)])

result.shape

test_image.shape

